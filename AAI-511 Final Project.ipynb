{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Team Project: Music Genre and Composer Classification Using Deep Learning\n",
    "\n",
    "## Introduction\n",
    "Music is a form of art that is ubiquitous and has a rich history. Different composers have created music with their unique styles and compositions. However, identifying the composer of a particular piece of music can be a challenging task, especially for novice musicians or listeners. The proposed project aims to use deep learning techniques to identify the composer of a given piece of music accurately.\n",
    "\n",
    "## Objective\n",
    "The primary objective of this project is to develop a deep learning model that can predict the composer of a given musical score accurately. The project aims to accomplish this objective by using two deep learning techniques: Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN).\n",
    "\n",
    "## Dataset\n",
    "The project will use a dataset consisting of musical scores from various composers.\n",
    "\n",
    "The dataset contains the midi files of compositions from well-known classical composers like Bach, Beethoven, Chopin, and Mozart. The dataset should be labeled with the name of the composer for each score.\n",
    "\n",
    "1-Bach  \n",
    "2-Beethoven  \n",
    "3-Chopin  \n",
    "4-Mozart  \n",
    "\n",
    "## Methodology\n",
    "The proposed project will be implemented using the following steps:\n",
    "\n",
    "1. **Data Collection**: Data is collected and provided to you.\n",
    "2. **Data Pre-processing**: Convert the musical scores into a format suitable for deep learning models. This involves converting the musical scores into MIDI files and applying data augmentation techniques.\n",
    "3. **Feature Extraction**: Extract features from the MIDI files, such as notes, chords, and tempo, using music analysis tools.\n",
    "4. **Model Building**: Develop a deep learning model using LSTM and CNN architectures to classify the musical scores according to the composer.\n",
    "5. **Model Training**: Train the deep learning model using the pre-processed and feature-extracted data.\n",
    "6. **Model Evaluation**: Evaluate the performance of the deep learning model using accuracy, precision, and recall metrics.\n",
    "7. **Model Optimization**: Optimize the deep learning model by fine-tuning hyperparameters.\n",
    "\n",
    "## Deliverables\n",
    "There are **two** deliverables for this Final Project:\n",
    "\n",
    "1. **Project Report**: A comprehensive documentation/report that describes the methodology, data pre-processing steps, feature extraction techniques, model architecture, and training process for reproducibility and future reference. Write your technical report in APA 7 style. Please submit the report in PDF format and use the File naming convention DeliverableName-TeamNumber.pdf; for example, **Project_Report-Team1.pdf**\n",
    "    - Your report should:\n",
    "        - contain a reference list that includes any external sources, libraries, or frameworks used during the project, including proper citations or acknowledgments.\n",
    "        - include a concluding section or markdown cell that summarizes the project, highlights key findings, and suggests any potential future improvements or extensions to the work.\n",
    "2. **Project Notebook**: A Jupyter Notebook file (.ipynb) that contains the entire project code, including data pre-processing, feature extraction, model building, training, evaluation, and any additional analysis or visualizations performed during the project.\n",
    "    - This deliverable will be exported from a Jupyter Notebook and submitted as a PDF or HTML file.\n",
    "\n",
    "## Conclusion\n",
    "The proposed project aims to use deep learning techniques to accurately predict the composer of a given musical score. The project will be implemented using LSTM and CNN architectures and will involve data pre-processing, feature extraction, model building, training, and evaluation. The final model can be used by novice musicians, listeners, and music enthusiasts to identify the composer of a musical piece accurately.\n",
    "\n",
    "**NOTE**: Team members may not get the same grade on the Final Team Project, depending on each team member's level of contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and File Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 00:23:16.575733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Data processing and numerical operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "\n",
    "# MIDI processing\n",
    "import pretty_midi as pm\n",
    "import mido\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Deep learning frameworks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Conv2D, MaxPooling2D, Dense, Flatten, Concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import torch as pt\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_theme(style='whitegrid', palette='deep')\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../aai-511_group1/midiclassics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_midi_file(file_path):\n",
    "    midi_data = pm.PrettyMIDI(file_path)\n",
    "    \n",
    "    info = {\n",
    "        'filename': file_path.split('/')[-1],\n",
    "        'total_duration': midi_data.get_end_time(),\n",
    "        'tempo': midi_data.estimate_tempo(),\n",
    "        'time_signature_changes': len(midi_data.time_signature_changes),\n",
    "        'key_signature_changes': len(midi_data.key_signature_changes),\n",
    "        'number_of_instruments': len(midi_data.instruments),\n",
    "    }\n",
    "    \n",
    "    all_notes = []\n",
    "    all_control_changes = []\n",
    "    all_pitch_bends = []\n",
    "    \n",
    "    for i, instrument in enumerate(midi_data.instruments):\n",
    "        info[f'instrument_{i}_name'] = instrument.name\n",
    "        info[f'instrument_{i}_program'] = instrument.program\n",
    "        info[f'instrument_{i}_is_drum'] = instrument.is_drum\n",
    "        info[f'instrument_{i}_note_count'] = len(instrument.notes)\n",
    "        \n",
    "        for note in instrument.notes:\n",
    "            all_notes.append({\n",
    "                'track': i,\n",
    "                'type': 'note',\n",
    "                'start': note.start,\n",
    "                'end': note.end,\n",
    "                'pitch': note.pitch,\n",
    "                'velocity': note.velocity\n",
    "            })\n",
    "        \n",
    "        for cc in instrument.control_changes:\n",
    "            all_control_changes.append({\n",
    "                'track': i,\n",
    "                'type': 'control_change',\n",
    "                'start': cc.time,\n",
    "                'number': cc.number,\n",
    "                'value': cc.value\n",
    "            })\n",
    "        \n",
    "        for pb in instrument.pitch_bends:\n",
    "            all_pitch_bends.append({\n",
    "                'track': i,\n",
    "                'type': 'pitch_bend',\n",
    "                'start': pb.time,\n",
    "                'value': pb.pitch\n",
    "            })\n",
    "    \n",
    "    # Tempo changes\n",
    "    tempo_times, tempo_values = midi_data.get_tempo_changes()\n",
    "    tempo_changes = [{\n",
    "        'type': 'tempo_change',\n",
    "        'start': tempo_times[i],\n",
    "        'tempo': tempo_values[i]\n",
    "    } for i in range(len(tempo_times))]\n",
    "    \n",
    "    return info, all_notes, all_control_changes, all_pitch_bends, tempo_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_midi_directory(root_dir, bach_limit=250):\n",
    "    data = []\n",
    "    all_notes = []\n",
    "    all_control_changes = []\n",
    "    all_pitch_bends = []\n",
    "    all_tempo_changes = []\n",
    "    \n",
    "    bach_files = []\n",
    "\n",
    "    for composer in os.listdir(root_dir):\n",
    "        composer_dir = os.path.join(root_dir, composer)\n",
    "        if os.path.isdir(composer_dir):\n",
    "            if composer.lower() == 'bach':\n",
    "                # to handle the file imbalance, we walk all of Bach's files first\n",
    "                # then select 250 randomly and process them\n",
    "                for root, _, files in os.walk(composer_dir):\n",
    "                    bach_files.extend([os.path.join(root, file) for file in files if file.lower().endswith(('.mid', '.midi'))])\n",
    "                if len(bach_files) > bach_limit:\n",
    "                    bach_files = random.sample(bach_files, bach_limit)\n",
    "                for file_path in tqdm(bach_files, desc=f\"Processing Bach (limited to {bach_limit})\"):\n",
    "                    process_file(file_path, 'Bach', data, all_notes, all_control_changes, all_pitch_bends, all_tempo_changes)\n",
    "            else:\n",
    "                # collect and process remaining composers\n",
    "                for root, _, files in os.walk(composer_dir):\n",
    "                    for file in tqdm(files, desc=f\"Processing {composer}\"):\n",
    "                        if file.lower().endswith(('.mid', '.midi')):\n",
    "                            file_path = os.path.join(root, file)\n",
    "                            process_file(file_path, composer, data, all_notes, all_control_changes, all_pitch_bends, all_tempo_changes)\n",
    "\n",
    "    df_info = pd.DataFrame(data)\n",
    "    df_notes = pd.DataFrame(all_notes)\n",
    "    df_control_changes = pd.DataFrame(all_control_changes)\n",
    "    df_pitch_bends = pd.DataFrame(all_pitch_bends)\n",
    "    df_tempo_changes = pd.DataFrame(all_tempo_changes)\n",
    "   \n",
    "    return df_info, df_notes, df_control_changes, df_pitch_bends, df_tempo_changes\n",
    "\n",
    "def process_file(file_path, composer, data, all_notes, all_control_changes, all_pitch_bends, all_tempo_changes):\n",
    "    try:\n",
    "        info, notes, control_changes, pitch_bends, tempo_changes = analyze_midi_file(file_path)\n",
    "        info['composer'] = composer\n",
    "        data.append(info)\n",
    "        \n",
    "        # unique ID for each file\n",
    "        file_id = len(data) - 1 \n",
    "        \n",
    "        for note in notes:\n",
    "            note['file_id'] = file_id\n",
    "            all_notes.append(note)\n",
    "        \n",
    "        for cc in control_changes:\n",
    "            cc['file_id'] = file_id\n",
    "            all_control_changes.append(cc)\n",
    "        \n",
    "        for pb in pitch_bends:\n",
    "            pb['file_id'] = file_id\n",
    "            all_pitch_bends.append(pb)\n",
    "        \n",
    "        for tc in tempo_changes:\n",
    "            tc['file_id'] = file_id\n",
    "            all_tempo_changes.append(tc)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "df_info, df_notes, df_control_changes, df_pitch_bends, df_tempo_changes = process_midi_directory(root_dir)\n",
    "\n",
    "# saving to CSV for reporducability and save time processing files\n",
    "df_info.to_csv('midi_info.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "df_notes.to_csv('midi_notes.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "df_control_changes.to_csv('midi_control_changes.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "df_pitch_bends.to_csv('midi_pitch_bends.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "df_tempo_changes.to_csv('midi_tempo_changes.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "display(df_info.head())\n",
    "display(df_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add file_id to df_info\n",
    "df_info['file_id'] = df_info.index\n",
    "\n",
    "# Group notes by file_id and create features\n",
    "note_features = df_notes.groupby('file_id').agg({\n",
    "    'pitch': ['mean', 'std', 'min', 'max'],\n",
    "    'velocity': ['mean', 'std', 'min', 'max'],\n",
    "    'start': ['min', 'max'],\n",
    "    'end': ['max']\n",
    "}).reset_index()\n",
    "note_features.columns = ['file_id'] + [f'note_{col[0]}_{col[1]}' for col in note_features.columns[1:]]\n",
    "\n",
    "# Create features from control changes\n",
    "cc_features = df_control_changes.groupby('file_id').agg({\n",
    "    'number': ['nunique'],\n",
    "    'value': ['mean', 'std']\n",
    "}).reset_index()\n",
    "cc_features.columns = ['file_id'] + [f'cc_{col[0]}_{col[1]}' for col in cc_features.columns[1:]]\n",
    "\n",
    "# Create features from pitch bends\n",
    "pb_features = df_pitch_bends.groupby('file_id').agg({\n",
    "    'value': ['mean', 'std', 'min', 'max']\n",
    "}).reset_index()\n",
    "pb_features.columns = ['file_id'] + [f'pb_{col[0]}_{col[1]}' for col in pb_features.columns[1:]]\n",
    "\n",
    "# Create features from tempo changes\n",
    "tempo_features = df_tempo_changes.groupby('file_id').agg({\n",
    "    'tempo': ['mean', 'std', 'min', 'max', 'count']\n",
    "}).reset_index()\n",
    "tempo_features.columns = ['file_id'] + [f'tempo_{col[0]}_{col[1]}' for col in tempo_features.columns[1:]]\n",
    "\n",
    "# Merge all features\n",
    "combined_features = df_info.merge(note_features, on='file_id', how='left')\\\n",
    "                           .merge(cc_features, on='file_id', how='left')\\\n",
    "                           .merge(pb_features, on='file_id', how='left')\\\n",
    "                           .merge(tempo_features, on='file_id', how='left')\n",
    "\n",
    "# Fill NaN values (in case some files don't have certain features)\n",
    "combined_features = combined_features.fillna(0)\n",
    "\n",
    "# print(combined_features.head())\n",
    "print(f'Combined Features Dataframe Shape: {combined_features.shape}')\n",
    "\n",
    "# Save the combined_features DataFrame to a CSV file\n",
    "combined_features.to_csv('combined_features.csv', index=False, escapechar='\\\\', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"DataFrame saved to 'combined_features.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(file_id, max_length=500):\n",
    "    file_notes = df_notes[df_notes['file_id'] == file_id].sort_values('start')\n",
    "    sequence = file_notes[['pitch', 'velocity', 'start', 'end']].values\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[:max_length]\n",
    "    else:\n",
    "        padding = np.zeros((max_length - len(sequence), 4))\n",
    "        sequence = np.vstack((sequence, padding))\n",
    "    return sequence\n",
    "\n",
    "# Create sequences for each file\n",
    "X_lstm = np.array([create_sequence(file_id) for file_id in combined_features['file_id']])\n",
    "y = combined_features['composer'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_piano_roll(file_id, time_steps=500, pitch_range=128):\n",
    "    file_notes = df_notes[df_notes['file_id'] == file_id]\n",
    "    piano_roll = np.zeros((time_steps, pitch_range))\n",
    "    for _, note in file_notes.iterrows():\n",
    "        start = int(note['start'] * time_steps / file_notes['end'].max())\n",
    "        end = int(note['end'] * time_steps / file_notes['end'].max())\n",
    "        pitch = int(note['pitch'])\n",
    "        piano_roll[start:end, pitch] = note['velocity']\n",
    "    return piano_roll\n",
    "\n",
    "# Create piano rolls for each file\n",
    "X_cnn = np.array([create_piano_roll(file_id) for file_id in combined_features['file_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize LSTM input\n",
    "scaler_lstm = StandardScaler()\n",
    "X_lstm_scaled = scaler_lstm.fit_transform(X_lstm.reshape(-1, X_lstm.shape[-1])).reshape(X_lstm.shape)\n",
    "\n",
    "# Normalize CNN input (assuming X_cnn is already created)\n",
    "scaler_cnn = StandardScaler()\n",
    "X_cnn_scaled = scaler_cnn.fit_transform(X_cnn.reshape(-1, X_cnn.shape[-1])).reshape(X_cnn.shape)\n",
    "\n",
    "# Normalize combined features\n",
    "X_combined = combined_features.select_dtypes(include=[np.number])\n",
    "scaler_combined = StandardScaler()\n",
    "X_combined_scaled = scaler_combined.fit_transform(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"X_lstm_scaled shape:\", X_lstm_scaled.shape)\n",
    "print(\"X_cnn_scaled shape:\", X_cnn_scaled.shape)\n",
    "print(\"X_combined_scaled shape:\", X_combined_scaled.shape)\n",
    "print(\"y_encoded shape:\", y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm_train, X_lstm_test, X_cnn_train, X_cnn_test, X_combined_train, X_combined_test, y_train, y_test = train_test_split(\n",
    "    X_lstm_scaled, X_cnn_scaled, X_combined_scaled, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"After splitting:\")\n",
    "print(\"X_lstm_train shape:\", X_lstm_train.shape)\n",
    "print(\"X_cnn_train shape:\", X_cnn_train.shape)\n",
    "print(\"X_combined_train shape:\", X_combined_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweaked Model --> 75% (Hopefully more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM input\n",
    "lstm_input = Input(shape=(X_lstm_train.shape[1], X_lstm_train.shape[2]))\n",
    "lstm_layer1 = LSTM(128, return_sequences=True)(lstm_input)\n",
    "lstm_layer1 = BatchNormalization()(lstm_layer1)\n",
    "lstm_layer1 = Dropout(0.3)(lstm_layer1)\n",
    "lstm_layer2 = LSTM(64)(lstm_layer1)\n",
    "lstm_layer2 = BatchNormalization()(lstm_layer2)\n",
    "lstm_out = Dropout(0.3)(lstm_layer2)\n",
    "\n",
    "# CNN input\n",
    "cnn_input = Input(shape=(X_cnn_train.shape[1], X_cnn_train.shape[2], 1))\n",
    "conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01))(cnn_input)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01))(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "flatten = Dropout(0.3)(flatten)\n",
    "\n",
    "# Combined features input\n",
    "combined_input = Input(shape=(X_combined_train.shape[1],))\n",
    "combined_dense = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(combined_input)\n",
    "combined_dense = BatchNormalization()(combined_dense)\n",
    "combined_dense = Dropout(0.3)(combined_dense)\n",
    "\n",
    "# Merge all features\n",
    "merged = Concatenate()([lstm_out, flatten, combined_dense])\n",
    "merged = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(len(np.unique(y)), activation='softmax')(merged)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[lstm_input, cnn_input, combined_input], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    [X_lstm_train, X_cnn_train, X_combined_train], \n",
    "    y_train, \n",
    "    validation_split=0.2, \n",
    "    epochs=100,  # Increased epochs\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Model --> 81-82% Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM input\n",
    "# lstm_input = Input(shape=(X_lstm_train.shape[1], X_lstm_train.shape[2]))\n",
    "# lstm_out = LSTM(64)(lstm_input)\n",
    "\n",
    "# # CNN input\n",
    "# cnn_input = Input(shape=(X_cnn_train.shape[1], X_cnn_train.shape[2], 1))\n",
    "# conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(cnn_input)\n",
    "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "# flatten = Flatten()(pool1)\n",
    "\n",
    "# # Combined features input\n",
    "# combined_input = Input(shape=(X_combined_train.shape[1],))\n",
    "\n",
    "# # Merge all features\n",
    "# merged = Concatenate()([lstm_out, flatten, combined_input])\n",
    "\n",
    "# # Output layer\n",
    "# output = Dense(len(np.unique(y)), activation='softmax')(merged)\n",
    "\n",
    "# # Create model\n",
    "# model = Model(inputs=[lstm_input, cnn_input, combined_input], outputs=output)\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Train model\n",
    "# history = model.fit(\n",
    "#     [X_lstm_train, X_cnn_train, X_combined_train], \n",
    "#     y_train, \n",
    "#     validation_split=0.2, \n",
    "#     epochs=50, \n",
    "#     batch_size=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Evaluation\n",
    "test_loss, test_accuracy = model.evaluate([X_lstm_test, X_cnn_test, X_combined_test], y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict([X_lstm_test, X_cnn_test, X_combined_test])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 2. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(np.unique(y_test)))\n",
    "plt.xticks(tick_marks, np.unique(y_test))\n",
    "plt.yticks(tick_marks, np.unique(y_test))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# 4. ROC Curve and AUC (for binary classification)\n",
    "# If binary classification\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    # For multi-class, you might want to use one-vs-rest ROC curves\n",
    "    y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "    n_classes = y_test_bin.shape[1]\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# 5. Learning Curves\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Demo\n",
    "These 8 files will be used for Demo purposes only. They were removed from the MIDI files dataset prior to models being trained, so the models will have never seen these files. They will be used in a final demonstration to determine if our efforts in being able to create a deep learning model to classify composers was successful.\n",
    "\n",
    "### Bach Files\n",
    "- *07 Rondo.mid*\n",
    "- *022602bv.mid*\n",
    "\n",
    "### Beethoven Files\n",
    "- *Sonatina In C.mid*\n",
    "- *137.MID*\n",
    "\n",
    "### Chopin Files\n",
    "- *Prelude n18 op28 \"Suicide\".mid*\n",
    "- *Ballad op53.mid*\n",
    "\n",
    "### Mozart Files\n",
    "- *Early Pieces n9 Allegretto.mid*\n",
    "- *Rondo.mid*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
